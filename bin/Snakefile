def all_which_input(wildcards):
    input_files = []
    
    # kraken2
    if not skipped(config['databases']['kraken2']):
        if config['keep_intermediate'] == True:
            x = expand(kraken2_dir + 'added/{sample}.done',
                       sample = config['samples_unique'])
            input_files += x	    
        input_files.append(os.path.join(kraken2_dir, 'hash.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'opts.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'taxo.k2d'))
        input_files.append(os.path.join(kraken2_dir, 'seqid2taxid.map'))

    # bracken
    if (not skipped(config['databases']['kraken2']) and
        not skipped(config['databases']['bracken'])):
    	x = expand(os.path.join(kraken2_dir, 'database{read_len}mers.kraken'),
	           read_len = config['params']['bracken_build_read_lens'])
        input_files += x

    # humann3    
    if not skipped(config['databases']['humann3_bowtie2']):
        input_files.append(os.path.join(humann3_dir, 'bowtie2_build.done'))
    if not skipped(config['databases']['humann3_diamond']):
        input_files.append(os.path.join(humann3_dir,'all_genes_annot.dmnd'))
    # if (not skipped(config['databases']['humann2_bowtie2']) and
    #     not skipped(config['databases']['humann2_diamond'])):
    #     if config['keep_intermediate'] == True:
    #         if config['use_ancient'] == True:                
    #             x = ancient(expand(annot_dir + 'prodigal/{sample}/annot.fna.gz',
    #                                sample = config['samples_unique']))
    #         else:			   
    #             x = expand(annot_dir + 'prodigal/{sample}/annot.fna.gz',
    #                        sample = config['samples_unique'])
    #         input_files += x
    #         if config['use_ancient'] == True:                	    
    #             x = ancient(expand(annot_dir + 'prodigal/{sample}/annot.faa.gz',
    #                                sample = config['samples_unique']))
    #         else:
    #             x = expand(annot_dir + 'prodigal/{sample}/annot.faa.gz',
    #                        sample = config['samples_unique'])
    #         input_files += x
    # if not skipped(config['databases']['humann2_bowtie2']):
    #     input_files.append(os.path.join(humann2_dir, 'bowtie2_build.done'))
    # if not skipped(config['databases']['humann2_diamond']):
    #     input_files.append(os.path.join(humann2_dir,'all_genes_annot.dmnd'))
    # humann2
    if not skipped(config['databases']['metaphlan3']):
        input_files.append(config['tmp_dir'] + 'species_specific.txt')
        
    # ret
    return input_files

# onsuccess/error
## funcs
def write_config(out_file):
    out_dir = os.path.split(out_file)[0]
    if not os.path.isdir(out_dir):
        os.makedirs(out_dir)
    config_tmp = {k:(v.to_string(max_rows=1, max_cols=10) if isinstance(v, pd.DataFrame) else v) \
                  for k,v in config.items()}
    with open(out_file, 'w') as outF:
        json.dump(config_tmp, outF, indent=4)

def file_atch(file_path, file_type):
   if os.path.isfile(file_path) and os.stat(file_path).st_size > 0:
       attach = '-a {}'.format(file_path)   
       file_path = os.path.split(file_path)[1]
       msg = 'See attached {} file: {}'.format(file_type, file_path)
   else:
       attach = ''
       file_path = os.path.split(file_path)[1]
       msg = 'WARNING: could not attach {}: {}'.format(file_type, file_path)
   return attach,msg
       
def send_email(rpt_file, email, config, pipeline='LL_pipeline', success=True):
    if find_executable('mutt') is None:
        print('WARNING: `mutt` not found. Not sending an email')
	return 0

    # json of config
    config_json = os.path.join(config['tmp_dir'], 'job_config.json')
    write_config(config_json)
    
    # email
    title = '{} finished successfully' if success is True else '{} => error occurred'
    title = title.format(pipeline)
    rpt_atch,rpt_msg = file_atch(rpt_file, 'job report')
    cfg_atch,cfg_msg = file_atch(config_json, 'pipeline config')    
    body = '\n'.join([rpt_msg, cfg_msg,
                      'Snakemake pipeline location: {}'.format(workflow.basedir)])
    cmd = "echo '{body}' | mutt {attch1} {attch2} -s '{title}' -- {email}"
    cmd = cmd.format(body=body, attch1=rpt_atch, attch2=cfg_atch, title=title, email=email)
    try:
        shell(cmd)
    except subprocess.CalledProcessError as e:
        cmd = "echo '{body}' | mutt {attch2} -s '{title}' -- {email}"
        cmd = cmd.format(body=body, attch2=cfg_atch, title=title, email=email)
        shell(cmd)
    
    # cleanup
    os.remove(rpt_file)
    os.remove(config_json)

def mk_cmd(success=True):
    msg = 'complete' if success is True else 'error'
    print('Pipeline {}! Creating report...'.format(msg))
    exe = os.path.join(config['pipeline']['script_folder'], 'log_summarize.py')
    rpt_file = os.path.join(config['tmp_dir'], 'job_report.csv')
    cmd = '{exe} {{log}} > {rpt_file}'.format(exe=exe, rpt_file=rpt_file)
    return rpt_file, cmd


## call
onsuccess:
    rpt_file,cmd = mk_cmd(success=True)
    try:
        shell(cmd)
    except subprocess.CalledProcessError:
        print('WARNING: could not parse snakemake log file')
    send_email(rpt_file, config['pipeline']['email'], config, pipeline='Struo2', success=True)

onerror:
    rpt_file,cmd = mk_cmd(success=False)
    try:
        shell(cmd)
    except subprocess.CalledProcessError:
        print('WARNING: could not parse snakemake log file')
    send_email(rpt_file, config['pipeline']['email'], config, pipeline='Struo2', success=False)
 

wildcard_constraints:
    sample="[^/]+"

rule prodigal:
    """
    Running prodigal on each genome
    """
    input:
        fasta = lambda wildcards: \
	  config['samples'].loc[wildcards.sample, config['fasta_file_path_col']]
    output:
        fna = temp(config['tmp_dir'] + 'prodigal/{sample}.fna'),
        faa = temp(config['tmp_dir'] + 'prodigal/{sample}.faa'),
        gbk = temp(config['tmp_dir'] + 'prodigal/{sample}.gbk')
    params:
        params = config['params']['prodigal']
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 59,
        n = lambda wildcards, attempt, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt * 2 * 8 + 8
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'prodigal/{sample}.log'
    benchmark:
        benchmark_dir + 'prodigal/{sample}.txt'
    shell:
        """
        gunzip -c {input.fasta} | \
          prodigal {params.params} \
          -o {output.gbk} -d {output.fna} -a {output.faa} \
          2> {log} 1>&2
        """    
        
rule diamond:
    """
    Annotating genes via diamond search of UniRef db
    """
    input:
        faa = config['tmp_dir'] + 'prodigal/{sample}.faa',
	dmnd_db = config['params']['diamond_db']
    output:
        hits = temp(config['tmp_dir'] + 'diamond/{sample}/hits.txt')
    params:
        params = config['params']['diamond'],
        cp_db = config['params']['diamond_db_to_mem'],
        tmp_dir = config['tmp_dir'] + '{sample}/'
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 60 * 10,
        n = lambda wildcards, attempt, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 3 + 1
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'diamond/{sample}.log'
    benchmark:
        benchmark_dir + 'diamond/{sample}.txt'
    shell:
        """
        DB="{input.dmnd_db}"
        TMPDIR="{params.tmp_dir}"
        mkdir -p $TMPDIR 2>> {log}

        # diamond run
        diamond blastp {params.params} \
           -q {input.faa} -d $DB -o {output.hits} \
           --tmpdir $TMPDIR --threads {threads} \
           --outfmt 6 qseqid sseqid pident length qstart qend qlen sstart send slen evalue \
           2>> {log} 1>&2
        """

if config['keep_intermediate'] == True:
    rule annotate_genes_KEEP:
        """
        Annotating genes via diamond search of UniRef db.
        Keeping results in order to speed up re-runs of the pipeline.
        """
        input:
            hits = config['tmp_dir'] + 'diamond/{sample}/hits.txt',
            fna = config['tmp_dir'] + 'prodigal/{sample}.fna',
            faa = config['tmp_dir'] + 'prodigal/{sample}.faa',
        output:
            fna = annot_dir + 'prodigal/{sample}/annot.fna.gz',
            faa = annot_dir + 'prodigal/{sample}/annot.faa.gz'
        params:
            tax = lambda wildcards: \
	      config['samples'].loc[wildcards.sample, config['taxonomy_col']],
            taxID = lambda wildcards: \
	      config['samples'].loc[wildcards.sample, config['taxID_col']],
            exe = config['pipeline']['script_folder'] + 'annotate_genes.py'
        resources:
            time = lambda wildcards, attempt: attempt ** 3 * 59,
            mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 6
        conda:
            '../envs/humann2.yaml'
        log:
            log_dir + 'annotate_genes/{sample}.log'
        benchmark:
            benchmark_dir + 'annotate_genes/{sample}.txt'
        shell:
            """
            OUTDIR=`dirname {output.fna}`
            {params.exe} --gzip --outdir $OUTDIR \
               --columns qseqid,sseqid,pident,length,qstart,qend,qlen,sstart,send,slen,evalue \
               {input.hits} {input.fna} {input.faa} "{params.tax}" {params.taxID} \
               2> {log} 1>&2
            """
else:
    rule annotate_genes_TMP:
        """
        Annotating genes via diamond search of UniRef db.
        The output is temporary in order to save on space.
        """
        input:
            hits = config['tmp_dir'] + 'diamond/{sample}/hits.txt',
            fna = config['tmp_dir'] + 'prodigal/{sample}.fna',
            faa = config['tmp_dir'] + 'prodigal/{sample}.faa',
        output:
            fna = temp(config['tmp_dir'] + 'prodigal/{sample}/annot.fna'),
            faa = temp(config['tmp_dir'] + 'prodigal/{sample}/annot.faa')
        params:
            tax = lambda wildcards: \
	      config['samples'].loc[wildcards.sample, config['taxonomy_col']],
            taxID = lambda wildcards: \
	      config['samples'].loc[wildcards.sample, config['taxID_col']],
            exe = config['pipeline']['script_folder'] + 'annotate_genes.py',
            prefix = config['tmp_dir'] + 'prodigal/{sample}'
        resources:
            time = lambda wildcards, attempt: attempt ** 3 * 59,
            mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 6
        conda:
            '../envs/humann2.yaml'
        log:
            log_dir + 'annotate_genes/{sample}.log'
        benchmark:
            benchmark_dir + 'annotate_genes/{sample}.txt'
        shell:
            """
            {params.exe} --prefix {params.prefix} \
               --columns qseqid,sseqid,pident,length,qstart,qend,qlen,sstart,send,slen,evalue \
               {input.hits} {input.fna} {input.faa} "{params.tax}" {params.taxID} \
               2> {log} 1>&2
            """

def which_input_cluster_genes_nuc(wildcards, type='nuc'):
    """Compressed input files? Nucleotide or protein?
    """
    if config['keep_intermediate'] == True:
        if type == 'nuc':
            if config['use_ancient'] == True:
                return ancient(annot_dir + 'prodigal/{sample}/annot.fna.gz')
            else:
                return annot_dir + 'prodigal/{sample}/annot.fna.gz'
        else:
            if config['use_ancient'] == True:
                return ancient(annot_dir + 'prodigal/{sample}/annot.faa.gz')
            else:
                return annot_dir + 'prodigal/{sample}/annot.faa.gz'                
    else:
        if type == 'nuc':
            return config['tmp_dir'] + 'prodigal/{sample}/annot.fna'
        else:
            return config['tmp_dir'] + 'prodigal/{sample}/annot.faa'
		 
rule cluster_genes_nuc:
    """
    Clustering genes (at nuc level) and taking the centroid. 
    This is done for each sample (genome).
    """
    input:
        fna = lambda wildcards: which_input_cluster_genes_nuc(wildcards, type='nuc'),
        faa = lambda wildcards: which_input_cluster_genes_nuc(wildcards, type='prot')
    output:
        reps = temp(config['tmp_dir'] + 'vsearch/{sample}_annot_reps.fna'),
        fna = annot_dir + 'nuc_filtered/{sample}_annot_reps.fna.gz',
        faa = annot_dir + 'prot_filtered/{sample}_annot_reps.faa.gz'
    params:
        params = config['params']['vsearch_per_genome'],
        exe = config['pipeline']['script_folder'] + 'filter_seqs.py',
        keep_int = config['keep_intermediate']
    threads:
        8
    resources:
        time = lambda wildcards, attempt: attempt ** 2 * 59,
        n = lambda wildcards, attempt, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt * 2
    conda:
        '../envs/humann2.yaml'
    log:
        log_dir + 'cluster_genes_nuc/{sample}.log'
    benchmark:
        benchmark_dir + 'cluster_genes_nuc/{sample}.txt'
    shell:
        """
        # cluster         
        if [ "{params.keep_int}" == "True" ]; then
          vsearch {params.params} \
            --threads {threads} \
            --cluster_fast <(gunzip -c {input.fna}) \
            --centroids {output.reps} \
            2> {log} 1>&2          

            # filter to just reps (duplicates removed)
            {params.exe} --gzip {output.reps} {input.faa} \
              {output.fna} {output.faa} 2> {log} 1>&2
        else
          vsearch {params.params} \
            --threads {threads} \
            --cluster_fast {input.fna} \
            --centroids {output.reps} \
            2> {log} 1>&2

            # filter to just reps (duplicates removed)
            {params.exe} --gzip {output.reps} {input.faa} \
              {output.fna} {output.faa} 2> {log} 1>&2
        fi
        """

localrules: cat_genes_nuc

def cat_genes_nuc_input(wildcards):
    """If user-provide sequences, adding them to the input file list
    """
    if config['use_ancient'] == True:
        x = ancient(expand(annot_dir + 'nuc_filtered/{sample}_annot_reps.fna.gz',
                           sample = config['samples_unique']))
    else:
        x = expand(annot_dir + 'nuc_filtered/{sample}_annot_reps.fna.gz',
                   sample = config['samples_unique'])
    if os.path.isfile(config['humann_nuc_seqs']):
        x.append(config['humann_nuc_seqs'])
    return(x)
    
rule cat_genes_nuc:
    """
    Combining genes: from genomes & user-provided genes
    """
    input:
        cat_genes_nuc_input
    output:
        temp(config['tmp_dir'] + 'humann2/all_genes_annot.fna')
    log:
        log_dir + 'cat_genes_nuc/all.log'
    benchmark:
        benchmark_dir + 'cat_genes_nuc/all.txt'
    run:
        import os,gzip
        with open(output[0], 'w') as outF:
            for F in input:
                with gzip.open(F, 'rb') as inF:
                    for line in inF:
                        outF.write(line.decode('utf-8'))
                
localrules: cat_genes_prot

def cat_genes_prot_input(wcs):
    if config['use_ancient'] == True:
        x = ancient(expand(annot_dir + 'prot_filtered/{sample}_annot_reps.faa.gz',
                    sample = config['samples_unique']))
    else:
        x = expand(annot_dir + 'prot_filtered/{sample}_annot_reps.faa.gz',
                   sample = config['samples_unique'])
    if os.path.isfile(config['humann_prot_seqs']):
        x.append(config['humann_prot_seqs'])
    return x

rule cat_genes_prot:
    """
    Combining genes: from genomes & user-provided genes
    """
    input:
        cat_genes_prot_input
    output:
        temp(config['tmp_dir'] + 'humann2/all_genes_annot.faa')
    log:
        log_dir + 'cat_genes_AA/all.log'
    benchmark:
        benchmark_dir + 'cat_genes_AA/all.txt'
    run:
        import os,gzip
        with open(output[0], 'w') as outF:
            for F in input:
                with gzip.open(F, 'rb') as inF:
                    for line in inF:
                        outF.write(line.decode('utf-8'))

if (config['humann_nuc_seqs'] != 'Skip' or config['humann_prot_seqs'] != 'Skip') and \
   not config['params']['vsearch_all'].startswith('Skip'):
    rule cluster_all_genes_nuc:
        """
        Clustering genes (at nuc level) and taking the centroid.        
        Clustering all genes together in order to remove redundancies.
        """
        input:
            fna = config['tmp_dir'] + 'humann2/all_genes_annot.fna',
            faa = config['tmp_dir'] + 'humann2/all_genes_annot.faa'
        output:
            reps = temp(config['tmp_dir'] + 'vsearch/all_annot_reps.fna'),
            fna = humann2_dir + 'all_genes_annot.fna.gz',
            faa = humann2_dir + 'all_genes_annot.faa.gz'
        params:
            params = config['params']['vsearch_all'],
            exe = config['pipeline']['script_folder'] + 'filter_seqs.py'
        threads:
            12
        resources:
            time = lambda wildcards, attempt: attempt ** 2 * 59,
            n = lambda wildcards, attempt, threads: threads,
            mem_gb_pt = lambda wildcards, attempt: attempt * 2 ** 2
        conda:
            '../envs/humann2.yaml'
        log:
            log_dir + 'cluster_all_genes_nuc/all.log'
        benchmark:
            benchmark_dir + 'cluster_all_genes_nuc/all.txt'
        shell:
            """
             # cluster
             vsearch {params.params} \
               --threads {threads} \
               --cluster_fast {input.fna} \
               --centroids {output.reps} \
               2> {log} 1>&2
    
            # filter AA seqs to just reps (duplicates removed)
            {params.exe} --gzip {output.reps} {input.faa} \
               {output.fna} {output.faa} 2> {log} 1>&2
            """
else:
    rule cluster_all_genes_nuc_SKIP:
        """
        Clustering genes (at nuc level) and taking the centroid
        """
        input:
            fna = config['tmp_dir'] + 'humann2/all_genes_annot.fna',
            faa = config['tmp_dir'] + 'humann2/all_genes_annot.faa'
        output:
            fna = os.path.join(humann2_dir, 'all_genes_annot.fna.gz'),
            faa = os.path.join(humann2_dir, 'all_genes_annot.faa.gz')
        threads:
            8
        resources:
            time = lambda wildcards, attempt: attempt ** 2 * 59,
            n = lambda wildcards, attempt, threads: threads,
            mem_gb_pt = lambda wildcards, attempt: attempt * 2 ** 2
        conda:
            '../envs/humann2.yaml'
        log:
            log_dir + 'cluster_all_genes_nuc/all.log'
        benchmark:
            benchmark_dir + 'cluster_all_genes_nuc/all.txt'
        shell:
            """
            pigz -p {threads} -c {input.fna} > {output.fna} 2> {log}
            pigz -p {threads} -c {input.faa} > {output.faa} 2>> {log}
            """

rule humann2_bowtie2_build:
    """
    Running bowtie2 build on combined, annotated genes 
    """
    input:
        os.path.join(humann2_dir, 'all_genes_annot.fna.gz')
    output:
        touch(os.path.join(humann2_dir, 'bowtie2_build.done'))
    params:
        prefix = humann2_dir + 'all_genes_annot'
    conda:
        '../envs/humann2.yaml'
    threads:
        24
    resources:
        time = lambda wildcards, attempt: attempt * 2 * 60 * 24,
        n = lambda wildcards, attempt, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 2 * 3 + 6
    log:
        log_dir + 'humann2_bowtie2_build/all.log'
    benchmark:
        log_dir + 'humann2_bowtie2_build/all.txt'
    shell:
        """
        bowtie2-build --threads {threads} \
          {input} {params.prefix} 2> {log} 1>&2

        # check that output exists
        OUTDIR=`dirname {params.prefix}`
        IDX_FILES=`find $OUTDIR -maxdepth 1 -name "*.bt2*"`
        IDX_FILES=`echo $IDX_FILES | perl -pe 's/ +/\n/g' | wc -l`
        if [ $IDX_FILES -lt 1 ]; then
          echo "ERROR: no bowtie2 index files found!"
          exit 1
        fi
        """    

rule humann2_diamond_makedb:
    """
    Running diamond makedb on combined, annotated genes 
    """
    input:
        os.path.join(humann2_dir, 'all_genes_annot.faa.gz')
    output:
        os.path.join(humann2_dir, 'all_genes_annot.dmnd')
    params:
        tmp_dir = config['tmp_dir']
    conda:
        '../envs/humann2.yaml'
    resources:
        time = lambda wildcards, attempt: attempt * 2 * 60 * 24,
        n = lambda wildcards, attempt, threads: threads,
        mem_gb_pt = lambda wildcards, attempt: attempt ** 3 * 12
    log:
        log_dir + 'humann2_diamond_makedb/all.log'
    benchmark:
        log_dir + 'humann2_diamond_makedb/all.txt'
    shell:
        """
        PREF=`echo {output} | perl -pe 's/\.[^.]+$//'`
        diamond makedb --in {input} -d $PREF 2> {log} 1>&2
        """    


